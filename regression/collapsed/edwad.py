from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import edward as ed
import math
import numpy as np
import pandas as pd
import tensorflow as tf
import time

from edward.models import Bernoulli
from edward.models import Deterministic
from edward.models import Empirical
from edward.models import Normal
from edward.models import ParamMixture

from tensorflow.python.framework import tensor_shape
from tensorflow.python.ops import array_ops

import numpy.random as random

from scipy.stats import norm
from tensorflow.python.ops import random_ops

from edward.models import RandomVariable
from tensorflow.contrib.distributions import Distribution
from tensorflow.contrib.distributions import NOT_REPARAMETERIZED

def normal_logpdf(x, mu, sigma):
    diff = tf.subtract(x, mu)
    diffsq = tf.multiply(diff, diff)
    sigmasq = tf.multiply(sigma, sigma)
    two_sigmasq = tf.multiply(tf.constant(2., dtype=tf.float32), sigmasq)
    return tf.add(
        tf.multiply(tf.constant(-0.5, dtype=tf.float32),
            tf.log(tf.multiply(tf.constant(math.pi), two_sigmasq))),
        tf.negative(tf.div(diffsq, two_sigmasq)))


class distributions_TwoNormals(Distribution):

    def __init__(self, mu, sigma1, sigma2, validate_args=True, allow_nan_stats=False, name="TwoNormals"):
        global n
        parameters = locals()
        with tf.name_scope(name, values=[mu, sigma1, sigma2]):
            with tf.control_dependencies([]):
                self._mu = tf.identity(mu, name="mu")
                self._sigma1 = tf.identity(sigma1, name="sigma1")
                self._sigma2 = tf.identity(sigma2, name="sigma2")
        super(distributions_TwoNormals, self).__init__(
            dtype=self._mu.dtype,
            reparameterization_type=NOT_REPARAMETERIZED,
            validate_args=validate_args,
            allow_nan_stats=allow_nan_stats,
            parameters=parameters,
            graph_parents=[self._mu, self._sigma1, self._sigma2],
            name=name)

    @property
    def mu(self):
        return self._mu

    @property
    def sigma1(self):
        return self._sigma1

    @property
    def sigma2(self):
        return self._sigma2

    def _batch_shape_tensor(self):
        return array_ops.shape(self.mu)

    def _batch_shape(self):
        return self.mu.shape

    def _event_shape_tensor(self):
        return constant_op.constant([], dtype=dtypes.int32)

    def _event_shape(self):
        return tensor_shape.scalar()

    def _log_prob(self, value):
        l1 = tf.add(normal_logpdf(value, self._mu, self._sigma1), tf.constant(math.log(0.5)))
        l2 = tf.add(normal_logpdf(value, self._mu, self._sigma2), tf.constant(math.log(0.5)))
        m = tf.maximum(l1, l2)
        return m + tf.log(tf.add(tf.exp(tf.subtract(l1, m)), tf.exp(tf.subtract(l2, m))))

    # NOTE: sample isn't used in our algorithm..
    def _sample_n(self, my_n, seed=None):
        shape = array_ops.concat([[my_n], self.batch_shape_tensor()], 0)
        sampled = random_ops.random_normal(shape=shape, mean=float("nan"), stddev=1., dtype=self.mu.dtype, seed=seed)
        return sampled



# Generate random variable class similar to autogenerated ones from TensorFlow.
def __init__(self, *args, **kwargs):
    RandomVariable.__init__(self, *args, **kwargs)


_name = 'TwoNormals'
_candidate = distributions_TwoNormals
__init__.__doc__ = _candidate.__init__.__doc__
_globals = globals()
_params = {'__doc__': _candidate.__doc__,
           '__init__': __init__}
_globals[_name] = type(_name, (RandomVariable, _candidate), _params)

# test logpdf of TwoNormals...
sess = ed.get_session()
mu=tf.constant(1.2, dtype=tf.float32)
std1 = tf.constant(0.5, dtype=tf.float32)
std2 = tf.constant(0.2, dtype=tf.float32)
x = tf.constant(2.3, dtype=tf.float32)
lpdf = TwoNormals(mu, std1, std2)._log_prob(x)
print(sess.run([lpdf])[0])
assert np.isclose(sess.run([lpdf])[0], -3.3389309434634598, rtol=0.0001)


# do the experiment
train_df = pd.read_csv("../train.csv")
train_xs = np.array(train_df["xs"].tolist())
train_ys = np.array(train_df["ys"].tolist())
n = len(train_xs)
print("n: ", n)

prob_outlier = 0.5
xs = tf.Variable(train_xs.astype(np.float32), trainable=False)
slope = Normal(loc=0.0, scale=2.0)
intercept = Normal(loc=0.0, scale=2.0)
inlier_log_var = Normal(loc=0.0, scale=1.0)
outlier_log_var = Normal(loc=0.0, scale=1.0)
inlier_std = tf.sqrt(tf.exp(inlier_log_var))
outlier_std = tf.sqrt(tf.exp(outlier_log_var))
mus = tf.add(tf.multiply(slope, xs), intercept)
ys = TwoNormals(mus, tf.fill([n], inlier_std), tf.fill([n], outlier_std))

import matplotlib.pyplot as plt

# plot some data to test the prior is correct
def sample_from_prior():
    sess = ed.get_session()
    (slope_est, intercept_est, inlier_log_var_est, outlier_log_var_est, inlier_std_est, outlier_std_est, mus_est, ys_est) = sess.run(
        [slope, intercept, inlier_log_var, outlier_log_var, inlier_std, outlier_std, mus, ys], feed_dict={xs: train_xs})
    print('Initial parameters:')
    print(slope_est)
    print(intercept_est)
    print(inlier_std_est)
    print(outlier_std_est)
    print(mus_est)
    plt.figure()
    plt.plot(train_xs, mus_est, color="blue")
    plt.fill_between(train_xs, mus_est-2*inlier_std_est, mus_est+2*inlier_std_est, color="black", alpha=0.2)
    plt.fill_between(train_xs, mus_est-2*outlier_std_est, mus_est+2*outlier_std_est, color="black", alpha=0.2)
    plt.scatter(train_xs, ys_est, s=5, color="black")
    plt.savefig("prior.png")

sample_from_prior()

def randn(size):
    arr = norm.rvs(size=size).astype(np.float32)
    return arr


class Sampler():

    def __init__(self, num_iter):
        self.num_iter = num_iter

        # storage for samples
        self.q_slope = Empirical(params=tf.get_variable("q_slope_%s" % (num_iter,), [num_iter], dtype=tf.float32, initializer=tf.random_normal_initializer()))
        self.q_intercept = Empirical(params=tf.get_variable("q_intercept_%s" % (num_iter,), [num_iter], dtype=tf.float32, initializer=tf.random_normal_initializer()))
        self.q_inlier_log_var = Empirical(params=tf.get_variable("q_inlier_log_var_%s" % (num_iter,), [num_iter], dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=2)))
        self.q_outlier_log_var = Empirical(params=tf.get_variable("q_outlier_log_var_%s" % (num_iter,), [num_iter], dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=2)))

        data_ys = {ys: train_ys}
        data_slope = {slope : self.q_slope}
        data_intercept = {intercept : self.q_intercept}
        data_inlier_log_var = {inlier_log_var : self.q_inlier_log_var}
        data_outlier_log_var = {outlier_log_var : self.q_outlier_log_var}

         # slope_update
        proposal = Normal(loc=slope, scale=0.5)
        data = {}
        data.update(data_ys)
        data.update(data_intercept)
        data.update(data_inlier_log_var)
        data.update(data_outlier_log_var)
        self.slope_update = ed.MetropolisHastings({slope : self.q_slope},
                                             {slope: proposal},
                                             data=data)

        # intercept update
        proposal = Normal(loc=intercept, scale=0.5)
        data = {}
        data.update(data_ys)
        data.update(data_slope)
        data.update(data_inlier_log_var)
        data.update(data_outlier_log_var)
        self.intercept_update = ed.MetropolisHastings({intercept: self.q_intercept},
                                                 {intercept: proposal},
                                                 data=data)

        # inlier_log_var update
        proposal = Normal(loc=inlier_log_var, scale=0.5)
        data = {}
        data.update(data_ys)
        data.update(data_slope)
        data.update(data_intercept)
        data.update(data_outlier_log_var)
        self.inlier_log_var_update = ed.MetropolisHastings({inlier_log_var: self.q_inlier_log_var},
                                                      {inlier_log_var: proposal},
                                                      data=data)

        # outlier_log_var update
        proposal = Normal(loc=outlier_log_var, scale=0.5)
        data = {}
        data.update(data_ys)
        data.update(data_slope)
        data.update(data_intercept)
        data.update(data_inlier_log_var)
        self.outlier_log_var_update = ed.MetropolisHastings({outlier_log_var: self.q_outlier_log_var},
                                                       {outlier_log_var: proposal},
                                                       data=data)

        self.hmc_inference = ed.HMC({slope: self.q_slope, intercept: self.q_intercept, inlier_log_var: self.q_inlier_log_var, outlier_log_var: self.q_outlier_log_var}, data={ys: train_ys})
        self.hmc_inference.initialize(step_size=0.01, n_print=10)#step_size=0.01) # step_size

    def sample_hmc(self):
        sess = ed.get_session()
        tf.global_variables_initializer().run()
        start_time = time.time()
        for i in range(self.num_iter):
            self.hmc_inference.update()
        elapsed = time.time() - start_time
        print("elapsed (ms): ", elapsed * 1000)
        return (elapsed, sess.run([self.q_slope.params[-1], self.q_intercept.params[-1], self.q_outlier_log_var.params[-1], self.q_inlier_log_var.params[-1]]))


    def sample(self):
        self.slope_update.initialize(n_iter=self.num_iter)
        self.intercept_update.initialize(n_iter=self.num_iter)
        self.inlier_log_var_update.initialize(n_iter=self.num_iter)
        self.outlier_log_var_update.initialize(n_iter=self.num_iter)
        sess = ed.get_session()
        tf.global_variables_initializer().run()
        start = time.time()
        for iter in range(self.num_iter):
            self.slope_update.update()
            self.intercept_update.update()
            self.inlier_log_var_update.update()
            self.outlier_log_var_update.update()
        elapsed = time.time() - start
        return (elapsed, sess.run([self.q_slope.params[-1], self.q_intercept.params[-1], self.q_inlier_log_var.params[-1], self.q_outlier_log_var.params[-1]]))


num_reps = 20
num_iters_col = []
slope_col = []
intercept_col = []
inlier_log_var_col = []
outlier_log_var_col = []
elapsed_col = []
prob_outlier_col = []
for num_iters in [1, 2, 3, 5, 7, 10, 20, 30, 50, 70, 100, 200, 300, 500, 700, 1000]:
    print("num_iters: %s" % (num_iters,))
    sampler = Sampler(num_iters)
    for rep in range(num_reps):
        start = time.time()
        #(elapsed, (sampled_slope, sampled_intercept, sampled_inlier_log_var, sampled_outlier_log_var)) = sampler.sample()
        (elapsed, (sampled_slope, sampled_intercept, sampled_inlier_log_var, sampled_outlier_log_var)) = sampler.sample_hmc()
        print(sampled_slope, " ", sampled_intercept, " ", sampled_inlier_log_var, " ", sampled_outlier_log_var)
        slope_col.append(sampled_slope)
        intercept_col.append(sampled_intercept)
        inlier_log_var_col.append(sampled_inlier_log_var)
        outlier_log_var_col.append(sampled_outlier_log_var)
        elapsed_col.append(elapsed * 1000)
        prob_outlier_col.append(prob_outlier)
        num_iters_col.append(num_iters)

results = pd.DataFrame({"slope" : slope_col, "intercept" : intercept_col,
              "inlier_log_var" : inlier_log_var_col, "outlier_log_var" : outlier_log_var_col,
              "elapsed" : elapsed_col, "num_steps" : num_iters_col, "prob_outlier" : prob_outlier_col})
results.to_csv("edward_hmc.csv")
